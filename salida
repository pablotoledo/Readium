Calculating tokens for files...
Processed 1/19 files...Processed 11/19 files...Processed 19 files.
       Directory Token Tree        
â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ            â”ƒ       â”ƒ      Token â”ƒ
â”ƒ Directory  â”ƒ Files â”ƒ      Count â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ .          â”‚ 4     â”‚      1,877 â”‚
â”‚ â””â”€         â”‚       â”‚         36 â”‚
â”‚ .pre-commâ€¦ â”‚       â”‚            â”‚
â”‚ â””â”€         â”‚       â”‚      1,481 â”‚
â”‚ README.md  â”‚       â”‚            â”‚
â”‚ â””â”€ pr.sh   â”‚       â”‚        198 â”‚
â”‚ â””â”€         â”‚       â”‚        162 â”‚
â”‚ pyprojectâ€¦ â”‚       â”‚            â”‚
â”‚ .devcontaâ€¦ â”‚ 1     â”‚         66 â”‚
â”‚ â””â”€         â”‚       â”‚         66 â”‚
â”‚ devcontaiâ€¦ â”‚       â”‚            â”‚
â”‚ .github/wâ€¦ â”‚ 2     â”‚        110 â”‚
â”‚ â””â”€         â”‚       â”‚         47 â”‚
â”‚ publish.yâ€¦ â”‚       â”‚            â”‚
â”‚ â””â”€         â”‚       â”‚         63 â”‚
â”‚ test.yml   â”‚       â”‚            â”‚
â”‚ src/readiâ€¦ â”‚ 4     â”‚      2,333 â”‚
â”‚ â””â”€         â”‚       â”‚         14 â”‚
â”‚ __init__.â€¦ â”‚       â”‚            â”‚
â”‚ â””â”€ cli.py  â”‚       â”‚        452 â”‚
â”‚ â””â”€         â”‚       â”‚        382 â”‚
â”‚ config.py  â”‚       â”‚            â”‚
â”‚ â””â”€ core.py â”‚       â”‚      1,485 â”‚
â”‚ src/readiâ€¦ â”‚ 1     â”‚         41 â”‚
â”‚ â””â”€         â”‚       â”‚         41 â”‚
â”‚ error_hanâ€¦ â”‚       â”‚            â”‚
â”‚ tests      â”‚ 5     â”‚      1,847 â”‚
â”‚ â””â”€         â”‚       â”‚         30 â”‚
â”‚ test_basiâ€¦ â”‚       â”‚            â”‚
â”‚ â””â”€         â”‚       â”‚        363 â”‚
â”‚ test_exteâ€¦ â”‚       â”‚            â”‚
â”‚ â””â”€         â”‚       â”‚        774 â”‚
â”‚ test_readâ€¦ â”‚       â”‚            â”‚
â”‚ â””â”€         â”‚       â”‚        324 â”‚
â”‚ test_tokeâ€¦ â”‚       â”‚            â”‚
â”‚ â””â”€         â”‚       â”‚        356 â”‚
â”‚ test_url_â€¦ â”‚       â”‚            â”‚
â”‚ tests/unit â”‚ 1     â”‚        174 â”‚
â”‚ â””â”€         â”‚       â”‚        174 â”‚
â”‚ test_cli.â€¦ â”‚       â”‚            â”‚
â”‚ tests/uniâ€¦ â”‚ 1     â”‚         48 â”‚
â”‚ â””â”€         â”‚       â”‚         48 â”‚
â”‚ test_erroâ€¦ â”‚       â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total Files: 19
Total Tokens: 6,496
Summary:
Path analyzed: .
Files processed: 19
Token Tree generated with 19 files


Tree:
Documentation Structure:
â””â”€â”€ pr.sh
â””â”€â”€ .pre-commit-config.yaml
â””â”€â”€ pyproject.toml
â””â”€â”€ README.md
â””â”€â”€ tests/test_basic.py
â””â”€â”€ tests/test_token_tree.py
â””â”€â”€ tests/test_url_handling.py
â””â”€â”€ 
tests/test_extension_exclusion.py
â””â”€â”€ tests/test_readium.py
â””â”€â”€ tests/unit/test_cli.py
â””â”€â”€ 
tests/unit/utils/test_error_handlin
g.py
â””â”€â”€ .devcontainer/devcontainer.json
â””â”€â”€ .github/workflows/publish.yml
â””â”€â”€ .github/workflows/test.yml
â””â”€â”€ src/readium/config.py
â””â”€â”€ src/readium/__init__.py
â””â”€â”€ src/readium/core.py
â””â”€â”€ src/readium/cli.py
â””â”€â”€ 
src/readium/utils/error_handling.py


Content:
# Directory Token Tree

| Directory | Files | Token Count |
|-----------|-------|------------|
| **.** | 4 | 1,877 |
| â””â”€ .pre-commit-config.yaml | | 36
|
| â””â”€ README.md | | 1,481 |
| â””â”€ pr.sh | | 198 |
| â””â”€ pyproject.toml | | 162 |
| **.devcontainer** | 1 | 66 |
| â””â”€ devcontainer.json | | 66 |
| **.github/workflows** | 2 | 110 |
| â””â”€ publish.yml | | 47 |
| â””â”€ test.yml | | 63 |
| **src/readium** | 4 | 2,333 |
| â””â”€ __init__.py | | 14 |
| â””â”€ cli.py | | 452 |
| â””â”€ config.py | | 382 |
| â””â”€ core.py | | 1,485 |
| **src/readium/utils** | 1 | 41 |
| â””â”€ error_handling.py | | 41 |
| **tests** | 5 | 1,847 |
| â””â”€ test_basic.py | | 30 |
| â””â”€ test_extension_exclusion.py | 
| 363 |
| â””â”€ test_readium.py | | 774 |
| â””â”€ test_token_tree.py | | 324 |
| â””â”€ test_url_handling.py | | 356 |
| **tests/unit** | 1 | 174 |
| â””â”€ test_cli.py | | 174 |
| **tests/unit/utils** | 1 | 48 |
| â””â”€ test_error_handling.py | | 48 
|

**Total Files:** 19  
**Total Tokens:** 6,496


===================================
=============
File: pr.sh
===================================
=============
#!/bin/bash

# Script para generar un prompt de 
anÃ¡lisis de PR basado en el diff 
con main/master

# Determinar si la rama principal 
es 'main' o 'master'
MAIN_BRANCH="main"
if ! git show-ref --verify --quiet 
refs/heads/main; then
  if git show-ref --verify --quiet 
refs/heads/master; then
    MAIN_BRANCH="master"
  else
    echo "Error: Neither 'main' nor
'master' branch found."
    exit 1
  fi
fi

# Obtener la rama actual
CURRENT_BRANCH=$(git branch 
--show-current)

if [ "$CURRENT_BRANCH" == 
"$MAIN_BRANCH" ]; then
  echo "Error: You are currently on
the $MAIN_BRANCH branch. Please 
checkout a feature branch."
  exit 1
fi

# Obtener el diff
DIFF=$(git diff 
$MAIN_BRANCH..$CURRENT_BRANCH)

# Generar el prompt
PROMPT="# Pull Request Analysis 
Request

Please analyze the following Git 
diff from a pull request and 
provide a detailed contribution 
analysis in English.

## Expected Analysis Structure

1. **Summary of Changes**
   - Brief overview of the main 
modifications
   - Key components affected

2. **Technical Details**
   - Files modified/added/deleted
   - Key functions or methods 
changed
   - Code quality observations

3. **Implementation Analysis**
   - Approach taken
   - Design patterns used
   - Potential improvements

4. **Testing Considerations**
   - Tests added/modified
   - Test coverage
   - Areas that might need 
additional testing

5. **Documentation**
   - Documentation quality
   - Areas that might need more 
documentation

6. **Impact Assessment**
   - Potential impact on existing 
functionality
   - Performance considerations
   - Security implications (if any)

7. **Conclusion**
   - Overall assessment of the PR
   - Recommendations (approve, 
request changes, etc.)

## Git Diff

\`\`\`diff
$DIFF
\`\`\`
"

# Imprimir el prompt o guardarlo en
un archivo
if [ -n "$1" ]; then
  echo "$PROMPT" > "$1"
  echo "Prompt saved to $1"
else
  echo "$PROMPT"
fi


===================================
=============
File: .pre-commit-config.yaml
===================================
=============
repos:
  - repo: 
https://github.com/pre-commit/mirro
rs-mypy
    rev: "v1.5.1"
    hooks:
      - id: mypy

  - repo: 
https://github.com/psf/black
    rev: "23.9.1"
    hooks:
      - id: black

  - repo: 
https://github.com/pre-commit/mirro
rs-isort
    rev: "v5.10.1"
    hooks:
      - id: isort

  - repo: 
https://github.com/pre-commit/pre-c
ommit-hooks
    rev: "v4.4.0"
    hooks:
      - id: end-of-file-fixer
      - id: trailing-whitespace
      - id: check-yaml
      - id: check-json
        exclude: "^.devcontainer/"


===================================
=============
File: pyproject.toml
===================================
=============

name = "readium"
version = "0.4.1"
description = "A tool to extract 
and analyze documentation from 
repositories, directories, and 
URLs"
authors = [
    {name = "Pablo Toledo", email =
"pablotoledo@users.noreply.github.c
om"}
]
license = {text = "MIT"}
readme = "README.md"
requires-python = ">=3.10,<4.0"
classifiers = [
    "Development Status :: 3 - 
Alpha",
    "Environment :: Console",
    "Intended Audience :: 
Developers",
    "License :: OSI Approved :: MIT
License",
    "Operating System :: OS 
Independent",
    "Programming Language :: Python
:: 3",
    "Programming Language :: Python
:: 3.10",
    "Programming Language :: Python
:: 3.11",
    "Programming Language :: Python
:: 3.12",
    "Topic :: Software Development 
:: Documentation",
]


python = ">=3.10,<4.0"  # 
Actualizado aquÃ­ tambiÃ©n
click = ">=8.1.8,<9.0.0"
rich = ">=13.9.4,<14.0.0"
black = ">=24.10.0,<25.0.0"
isort = ">=5.12.0,<6.0.0"
markitdown = ">=0.0.1a3,<0.0.2"
pypdf = ">=3.0.1,<4.0.0"
trafilatura = ">=1.6.0,<2.0.0"
lxml = {extras = ["html-clean"], 
version = "^5.3.1"}
tiktoken = {version = ">=0.3.1", 
optional = true}


tokenizers = ["tiktoken"]


pytest = "*"
pytest-mock = "*"
mypy = "*"
black = "*"
isort = "*"
pre-commit = "*"
hatch = "*"


Homepage = 
"https://github.com/pablotoledo/rea
dium"
Repository = 
"https://github.com/pablotoledo/rea
dium.git"
Issues = 
"https://github.com/pablotoledo/rea
dium/issues"


readium = "readium.cli:main"


requires = ["poetry-core>=1.0.0"]
build-backend = 
"poetry.core.masonry.api"


profile = "black"
multi_line_output = 3
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = 
true
line_length = 88


===================================
=============
File: README.md
===================================
=============
# ðŸ“š Readium

A powerful Python tool for 
extracting, analyzing, and 
converting documentation from 
repositories, directories, and URLs
into accessible formats.

<p align="center">
  <img src="logo.webp" 
alt="Readium" width="80%">
</p>

## âœ¨ Features

- ðŸ“‚ **Extract documentation** from
local directories or Git 
repositories
  - Support for private 
repositories using tokens
  - Branch selection for Git 
repositories
  - Secure token handling and 
masking
- ðŸŒ **Process webpages and URLs** 
to convert directly to Markdown
  - Extract main content from 
documentation websites
  - Convert HTML to well-formatted 
Markdown
  - Support for tables, links, and 
images in converted content
- ðŸ”„ **Convert multiple document 
formats** to Markdown using 
MarkItDown integration
- ðŸŽ¯ **Target specific 
subdirectories** for focused 
analysis

## ðŸ”„ MarkItDown Integration

Readium can use 
[MarkItDown](https://github.com/mic
rosoft/markitdown) to convert a 
wide range of document formats 
directly to Markdown, including:

- PDF (`.pdf`)
- Word (`.docx`)
- Excel (`.xlsx`, `.xls`)
- PowerPoint (`.pptx`)
- HTML (`.html`, `.htm`)
- Outlook messages (`.msg`)

To enable this feature, use the 
`--use-markitdown` option in the 
CLI or set `use_markitdown=True` in
the Python API. MarkItDown will be 
used automatically for all 
compatible files.

**Note:** The `markitdown` Python 
package must be installed. It is 
included as a dependency, but you 
can install it manually with:
```bash
pip install markitdown
```

**Example CLI usage:**
```bash
readium /path/to/directory 
--use-markitdown
```

When enabled, the summary will 
indicate:
```
Using MarkItDown for compatible 
files
MarkItDown extensions: .pdf, .docx,
.xlsx, .pptx, .html, .msg
```
- âš¡ **Process a wide range of file
types**:
  - Documentation files (`.md`, 
`.mdx`, `.rst`, `.txt`)
  - Code files (`.py`, `.js`, 
`.java`, etc.)
  - Configuration files (`.yml`, 
`.toml`, `.json`, etc.)
  - Office documents with 
MarkItDown (`.pdf`, `.docx`, 
`.xlsx`, `.pptx`)
  - Webpages and HTML via direct 
URL processing
- ðŸŽ›ï¸ **Highly configurable**:
  - Customizable file size limits
  - Flexible file extension 
filtering
  - Directory exclusion patterns
  - Binary file detection
  - Debug mode for detailed 
processing information
- ðŸ” **Advanced error handling and 
debugging**:
  - Detailed debug logging
  - Graceful handling of 
unprintable content
  - Robust error reporting with 
Rich console support
- ðŸ“ **Split output for 
fine-tuning** language models

## ðŸš€ Installation

```bash
# Using pip
pip install readium

# Using poetry
poetry add readium
```

## ðŸ“‹ Usage

### Command Line Interface

**Basic usage:**
```bash
# Process a local directory
readium /path/to/directory

# Process a public Git repository
readium 
https://github.com/username/reposit
ory

# Process a specific branch of a 
Git repository
readium 
https://github.com/username/reposit
ory -b feature-branch

# Process a private Git repository 
with token
readium 
https://token@github.com/username/r
epository

# Process a webpage and convert to 
Markdown
readium 
https://example.com/documentation

# Save output to a file
readium /path/to/directory -o 
output.md

# Enable MarkItDown integration 
(for PDF, DOCX, etc.)
readium /path/to/directory 
--use-markitdown

# Focus on specific subdirectory
readium /path/to/directory 
--target-dir docs/
```

**Advanced options:**
```bash
# Customize file size limit (e.g., 
10MB)
readium /path/to/directory 
--max-size 10485760

# Add custom directories to exclude
(can be specified multiple times)
readium /path/to/directory 
--exclude-dir build --exclude-dir 
temp

# Or using the short form -x (can 
be repeated)
readium /path/to/directory -x build
-x temp

# Include additional file 
extensions
readium /path/to/directory 
--include-ext .cfg --include-ext 
.conf

# The CLI will print the final list
of excluded directories at runtime.

# Exclude specific file extensions 
(can be specified multiple times)
readium /path/to/directory 
--exclude-ext .json --exclude-ext 
.yml

# Enable debug mode for detailed 
processing information
readium /path/to/directory --debug

# Generate split files for 
fine-tuning
readium /path/to/directory 
--split-output ./training-data/

# Process URL with content 
preservation mode
readium https://example.com/docs 
--url-mode full

# Process URL with main content 
extraction (default)
readium https://example.com/docs 
--url-mode clean
```

**Note:**
- Do not use empty values with 
`-x`/`--exclude-dir`. Each value 
must be a valid directory name.
- The CLI will display the final 
list of excluded directories before
processing.

### Python API

```python
from readium import Readium, 
ReadConfig

# Configure the reader
config = ReadConfig(
    max_file_size=5 * 1024 * 1024, 
# 5MB limit
    target_dir='docs',             
# Optional target subdirectory
    use_markitdown=True,           
# Enable MarkItDown integration
    debug=True,                    
# Enable debug logging

    # Mostrar tabla de tokens por 
archivo/directorio
    show_token_tree=False,  # True 
para activar el token tree

    # MÃ©todo de conteo de tokens: 
'simple' (por palabras) o 
'tiktoken' (OpenAI, requiere 
tiktoken)
    token_calculation="simple",  # 
O "tiktoken"
)

# Initialize reader
reader = Readium(config)

# Process directory
summary, tree, content = 
reader.read_docs('/path/to/director
y')

# Process public Git repository
summary, tree, content = 
reader.read_docs('https://github.co
m/username/repo')

# Process specific branch of a Git 
repository
summary, tree, content = 
reader.read_docs(
    'https://github.com/username/re
po',
    branch='feature-branch'
)

# Process private Git repository 
with token
summary, tree, content = 
reader.read_docs('https://token@git
hub.com/username/repo')

# Process a webpage and convert to 
Markdown
summary, tree, content = 
reader.read_docs('https://example.c
om/documentation')

# Access results
print("Summary:", summary)
print("\nFile Tree:", tree)
print("\nContent:", content)
```

## ðŸŒ URL to Markdown

Readium can process web pages and 
convert them directly to Markdown:

```bash
# Process a webpage
readium 
https://example.com/documentation

# Save the output to a file
readium 
https://example.com/documentation 
-o docs.md

# Process URL preserving more 
content
readium 
https://example.com/documentation 
--url-mode full

# Process URL extracting only main 
content (default)
readium 
https://example.com/documentation 
--url-mode clean
```

### URL Conversion Configuration

The URL to Markdown conversion can 
be configured with several options:

- `--url-mode`: Processing mode 
(`clean` or `full`)
  - `clean` (default): Extracts 
only the main content, ignoring 
menus, ads, etc.
  - `full`: Attempts to preserve 
most of the page content

### Python API for URLs

```python
from readium import Readium, 
ReadConfig

# Configure with URL options
config = ReadConfig(
    url_mode="clean",  # 'clean' or
'full'
    include_tables=True,
    include_images=True,
    include_links=True,
    include_comments=False,
    debug=True
)

reader = Readium(config)

# Process a URL
summary, tree, content = 
reader.read_docs('https://example.c
om/documentation')

# Save the content
with open('documentation.md', 'w', 
encoding='utf-8') as f:
    f.write(content)
```

Readium uses 
(https://github.com/adbar/trafilatu
ra) for web content extraction and 
conversion, which is especially 
effective for extracting the main 
content from technical 
documentation, tutorials, and other
web resources.

## ðŸ”§ Configuration

The `ReadConfig` class supports the
following options:

```python
config = ReadConfig(
    # File size limit in bytes 
(default: 5MB)
    max_file_size=5 * 1024 * 1024,

    # Directories to exclude 
(extends default set)
    exclude_dirs={'custom_exclude',
'temp'},

    # Files to exclude (extends 
default set)
    exclude_files={'.custom_exclude
', '*.tmp'},

    # File extensions to include 
(extends default set)
    include_extensions={'.custom', 
'.special'},

    # File extensions to exclude 
(takes precedence over 
include_extensions)
    exclude_extensions={'.json', 
'.yml'},

    # Target specific subdirectory
    target_dir='docs',

    # Enable MarkItDown integration
    use_markitdown=True,

    # Specify extensions for 
MarkItDown processing
    markitdown_extensions={'.pdf', 
'.docx', '.xlsx'},

    # URL processing mode: 'clean' 
or 'full'
    url_mode='clean',

    # URL content options
    include_tables=True,
    include_images=True,
    include_links=True,
    include_comments=False,

    # Enable debug mode
    debug=False,

    # Mostrar tabla de tokens por 
archivo/directorio
    show_token_tree=False,  # True 
para activar el token tree

    # MÃ©todo de conteo de tokens: 
'simple' (por palabras) o 
'tiktoken' (OpenAI, requiere 
tiktoken)
    token_calculation="simple",  # 
O "tiktoken"
)
```

### Default Configuration

#### Default Excluded Directories
```python
DEFAULT_EXCLUDE_DIRS = {
    ".git", "node_modules", 
"__pycache__", "assets",
    "img", "images", "dist", 
"build", ".next",
    ".vscode", ".idea", "bin", 
"obj", "target",
    "out", ".venv", "venv", 
".gradle",
    ".pytest_cache", ".mypy_cache",
"htmlcov",
    "coverage", ".vs", "Pods"
}
```

#### Default Excluded Files
```python
DEFAULT_EXCLUDE_FILES = {
    ".pyc", ".pyo", ".pyd", 
".DS_Store",
    ".gitignore", ".env", 
"Thumbs.db",
    "desktop.ini", "npm-debug.log",
    "yarn-error.log", 
"pnpm-debug.log",
    "*.log", "*.lock"
}
```

#### Default Included Extensions
```python
DEFAULT_INCLUDE_EXTENSIONS = {
    ".md", ".mdx", ".txt", ".yml", 
".yaml", ".rst",
    ".py", ".js", ".ts", ".jsx", 
".tsx", ".java",
    # (Many more included - see 
config.py for complete list)
}
```

**Note:** If a file extension is 
specified in both 
`include_extensions` and 
`exclude_extensions`, the exclusion
takes precedence and files with 
that extension will not be 
processed.

#### Default MarkItDown Extensions
```python
MARKITDOWN_EXTENSIONS = {
    ".pdf", ".docx", ".xlsx", 
".xls",
    ".pptx", ".html", ".htm", 
".msg"
}
```

## ðŸ“œ Output Format

Readium generates three types of 
output:

1. **Summary**: Overview of the 
processing results
   ```
   Path analyzed: 
/path/to/directory
   Files processed: 42
   Target directory: docs
   Using MarkItDown for compatible 
files
   MarkItDown extensions: .pdf, 
.docx, .xlsx, ...
   ```

2. **Tree**: Visual representation 
of processed files
   ```
   Documentation Structure:
   â””â”€â”€ README.md
   â””â”€â”€ docs/guide.md
   â””â”€â”€ src/example.py
   ```

3. **Content**: Full content of 
processed files
   ```
   ================================
================
   File: README.md
   ================================
================
   [File content here]

   ================================
================
   File: docs/guide.md
   ================================
================
   [File content here]
   ```

## ðŸ”¢ Token Tree (Conteo de tokens 
por archivo/directorio)

Readium puede generar una tabla de 
conteo de tokens por archivo y 
directorio, Ãºtil para estimar el 
tamaÃ±o de los datos para modelos de
lenguaje o para anÃ¡lisis de 
documentaciÃ³n.

- El token tree muestra la 
estructura de carpetas/archivos 
junto con el nÃºmero de tokens 
estimados por cada uno.
- Puede usarse tanto desde la lÃ­nea
de comandos como desde la API 
Python.
- Permite elegir el mÃ©todo de 
conteo: rÃ¡pido (por palabras) o 
compatible con OpenAI (usando 
`tiktoken`).
- Requiere la instalaciÃ³n opcional 
de `tiktoken` para el mÃ©todo 
OpenAI.

### Ejemplo de salida
```
Token Tree:
â””â”€â”€ README.md (tokens: 120)
â””â”€â”€ docs/guide.md (tokens: 340)
â””â”€â”€ src/example.py (tokens: 210)
Total tokens: 670
```

### CLI: Uso de Token Tree

```bash
# Mostrar el token tree usando el 
mÃ©todo rÃ¡pido (por palabras)
readium /ruta/al/proyecto 
--token-tree

# Usar el mÃ©todo OpenAI (requiere 
tiktoken)
readium /ruta/al/proyecto 
--token-tree --token-method 
tiktoken

# Desactivar el token tree (por 
defecto)
readium /ruta/al/proyecto 
--no-token-tree
```

- `--token-tree` activa la tabla de
tokens.
- `--token-method` permite elegir 
entre `simple` (por palabras, por 
defecto) o `tiktoken` (requiere 
instalar tiktoken: `poetry install 
--with tokenizers`).

### Python API: Uso de Token Tree

```python
from readium import Readium, 
ReadConfig

config = ReadConfig(
    show_token_tree=True,          
# Activa el token tree
    token_calculation="tiktoken",  
# O "simple" para conteo por 
palabras
)
reader = Readium(config)
summary, tree, content = 
reader.read_docs("/ruta/al/proyecto
")
# El token tree estarÃ¡ incluido en 
el summary y/o tree
```

#### InstalaciÃ³n de tiktoken 
(opcional)

Para usar el mÃ©todo de conteo 
OpenAI, instala la dependencia 
opcional:

```bash
poetry install --with tokenizers
# o
pip install tiktoken
```

- Si `tiktoken` no estÃ¡ instalado y
seleccionas ese mÃ©todo, Readium 
mostrarÃ¡ un aviso y usarÃ¡ el mÃ©todo
simple.

---

## ðŸ“ Split Output for Fine-tuning

When using the `--split-output` 
option or setting 
`split_output_dir` in the Python 
API, Readium will generate 
individual files for each processed
document. This is particularly 
useful for creating datasets for 
fine-tuning language models.

Each output file:
- Has a unique UUID-based name 
(e.g., 
`123e4567-e89b-12d3-a456-4266141740
00.txt`)
- Contains metadata headers with:
  - Original file path
  - Base directory
  - UUID
- Includes the complete original 
content
- Is saved with UTF-8 encoding

Example output file structure:
```
Original Path: 
src/documentation/guide.md
Base Directory: /path/to/repository
UUID: 
123e4567-e89b-12d3-a456-42661417400
0
===================================
===============

[Original file content follows 
here]
```

### Usage Examples

Command Line:
```bash
# Basic split output
readium /path/to/repository 
--split-output ./training-data/

# Combined with other features
readium /path/to/repository \
    --split-output ./training-data/
\
    --target-dir docs \
    --use-markitdown \
    --debug

# Process a URL and create split 
files
readium https://example.com/docs \
    --split-output ./training-data/
\
    --url-mode clean
```

Python API:
```python
from readium import Readium, 
ReadConfig

# Configure with all relevant 
options
config = ReadConfig(
    target_dir='docs',
    use_markitdown=True,
    debug=True
)

reader = Readium(config)
reader.split_output_dir = 
"./training-data/"

# Process and generate split files
summary, tree, content = 
reader.read_docs('/path/to/reposito
ry')

# Process a URL and generate split 
files
summary, tree, content = 
reader.read_docs('https://example.c
om/docs')
```

## ðŸ› ï¸ Development

1. Clone the repository
   ```bash
   git clone 
https://github.com/pablotoledo/read
ium.git
   cd readium
   ```

2. Install development 
dependencies:
   ```bash
   # Using pip
   pip install -e "."

   # Or using Poetry
   poetry install --with dev
   ```

3. Install pre-commit hooks:
   ```bash
   pre-commit install
   ```

### Running Tests

```bash
# Run all tests
pytest

# Run tests without warnings
pytest -p no:warnings

# Run tests for specific Python 
version
poetry run pytest
```

## ðŸ¤ Contributing

Contributions are welcome! Please 
feel free to submit a Pull Request.
For major changes, please open an 
issue first to discuss what you 
would like to change.

1. Fork the repository
2. Create your feature branch (`git
checkout -b 
feature/amazing-feature`)
3. Commit your changes (`git commit
-m 'Add some amazing feature'`)
4. Push to the branch (`git push 
origin feature/amazing-feature`)
5. Open a Pull Request

## ðŸ“„ License

This project is licensed under the 
MIT License - see the LICENSE file 
for details.

## ðŸ™ Acknowledgments

- Microsoft and MarkItDown for 
their powerful document conversion 
tool
- Trafilatura for excellent web 
content extraction capabilities
- Rich library for beautiful 
console output
- Click for the powerful CLI 
interface


===================================
=============
File: tests/test_basic.py
===================================
=============
from readium import ReadConfig, 
Readium


def test_read_config():
    config = ReadConfig()
    assert config.max_file_size == 
5 * 1024 * 1024  # Default 5MB
    assert 
isinstance(config.exclude_dirs, 
set)
    assert 
isinstance(config.include_extension
s, set)


def test_readium_init():
    reader = Readium()
    assert reader.config is not 
None
    assert reader.markitdown is 
None


===================================
=============
File: tests/test_token_tree.py
===================================
=============
import tempfile
from pathlib import Path
from unittest.mock import patch, 
MagicMock

import pytest
from click.testing import CliRunner

from readium import ReadConfig, 
Readium
from readium.cli import main


@pytest.fixture
def temp_dir_with_files():
    """Create a temporary directory
with test files for token 
counting"""
    with 
tempfile.TemporaryDirectory() as 
tmp_dir:
        path = Path(tmp_dir)
        docs_dir = path / "docs"
        src_dir = path / "src"
        docs_dir.mkdir()
        src_dir.mkdir()
        files = {
            "README.md": "# Test 
Project\nThis is a test project for
token counting.",
            "docs/guide.md": "# 
User Guide\n\n" + "This is test 
content.\n" * 10,
            "docs/api.md": "# API 
Reference\n\n" + "API details 
here.\n" * 15,
            "src/main.py": "def 
main():\n    print('Hello 
world')\n\nif __name__ == 
'__main__':\n    main()",
        }
        for rel_path, content in 
files.items():
            file_path = path / 
rel_path
            file_path.parent.mkdir(
exist_ok=True)
            file_path.write_text(co
ntent)
        yield path

def test_estimate_tokens_simple():
    """Test token estimation with 
simple method"""
    config = 
ReadConfig(token_calculation="simpl
e")
    reader = Readium(config)
    assert 
reader.estimate_tokens("This is a 
test") > 0
    assert 
reader.estimate_tokens("") == 0
    short_text = "Short text"
    long_text = "Long text " * 100
    assert 
reader.estimate_tokens(long_text) >
reader.estimate_tokens(short_text)

@pytest.mark.skipif(
    True,  # Skip by default, can 
be enabled when tiktoken is 
installed
    reason="Requires optional 
tiktoken dependency"
)
def 
test_estimate_tokens_tiktoken():
    """Test token estimation with 
tiktoken method"""
    config = 
ReadConfig(token_calculation="tikto
ken")
    reader = Readium(config)
    assert 
reader.estimate_tokens("This is a 
test") > 0
    assert 
reader.estimate_tokens("") == 0

def 
test_generate_token_tree(temp_dir_w
ith_files):
    """Test token tree 
generation"""
    config = 
ReadConfig(show_token_tree=True)
    reader = Readium(config)
    with patch.object(reader, 
'estimate_tokens', 
return_value=100):
        files = [
            {"path": "README.md", 
"content": "Test content"},
            {"path": 
"docs/guide.md", "content": "Guide 
content"},
            {"path": "docs/api.md",
"content": "API content"},
            {"path": "src/main.py",
"content": "Python code"},
        ]
        token_tree = 
reader.generate_token_tree(files, 
temp_dir_with_files)
        assert "# Directory Token 
Tree" in token_tree
        assert "docs" in token_tree
        assert "src" in token_tree
        assert "README.md" in 
token_tree
        assert "guide.md" in 
token_tree
        assert "api.md" in 
token_tree
        assert "main.py" in 
token_tree
        assert "100" in token_tree
        assert "Total Files:" in 
token_tree
        assert "Total Tokens:" in 
token_tree

def 
test_read_docs_with_token_tree(temp
_dir_with_files):
    """Test integration of token 
tree with read_docs"""
    config = 
ReadConfig(show_token_tree=True)
    reader = Readium(config)
    summary, tree, content = 
reader.read_docs(temp_dir_with_file
s)
    assert "Token Tree generated" 
in summary
    assert "# Directory Token Tree"
in content
    assert "Documentation 
Structure:" in tree

def 
test_cli_with_token_tree(temp_dir_w
ith_files):
    """Test CLI with token tree 
option"""
    runner = CliRunner()
    result = runner.invoke(
        main, 
    )
    assert result.exit_code == 0
    assert "Token Tree generated" 
in result.output

def test_backward_compatibility():
    """Test that old functionality 
still works without token tree"""
    config = ReadConfig()
    reader = Readium(config)
    with patch.object(reader, 
'generate_token_tree') as 
mock_generate:
        with 
tempfile.TemporaryDirectory() as 
tmp_dir:
            path = Path(tmp_dir)
            (path / 
"file.md").write_text("Test 
content")
            reader.read_docs(path)
            mock_generate.assert_no
t_called()

def test_url_with_token_tree():
    """Test token tree works with 
URLs"""
    config = 
ReadConfig(show_token_tree=True)
    reader = Readium(config)
    with 
patch("readium.core.convert_url_to_
markdown") as mock_convert:
        mock_convert.return_value =
("Test Document", "# Test Content")
        summary, tree, content = 
reader.read_docs("https://example.c
om/docs")
        assert "Token Tree 
generated" in summary
        assert "# Directory Token 
Tree" in content


===================================
=============
File: tests/test_url_handling.py
===================================
=============
# tests/test_url_handling.py
import os
from pathlib import Path
from unittest.mock import Mock, 
patch

import pytest

from readium import ReadConfig, 
Readium
from readium.core import 
convert_url_to_markdown, is_url


def test_is_url():
    """Test URL detection"""
    assert 
is_url("https://github.com")
    assert 
is_url("http://example.com/docs")
    assert not is_url("github.com")
# No scheme
    assert not 
is_url("/local/path")
    assert not 
is_url("git@github.com:user/repo.gi
t")  # SSH URL
    assert not 
is_url("https://github.com/user/rep
o.git")  # Git URL


@patch("trafilatura.fetch_url")
@patch("trafilatura.extract")
@patch("trafilatura.extract_metadat
a")
def 
test_convert_url_to_markdown(mock_m
etadata, mock_extract, mock_fetch):
    """Test converting a URL to 
Markdown"""
    # Setup mocks
    mock_fetch.return_value = 
"<html><body><h1>Test</h1><p>Conten
t</p></body></html>"
    mock_extract.return_value = "# 
Test\n\nContent"

    # Setup metadata mock
    metadata_mock = Mock()
    metadata_mock.title = "Test 
Page"
    mock_metadata.return_value = 
metadata_mock

    # Test conversion
    title, markdown = 
convert_url_to_markdown("https://ex
ample.com/docs")

    # Assertions
    assert title == "Test Page"
    assert markdown == "# 
Test\n\nContent"
    mock_fetch.assert_called_once_w
ith("https://example.com/docs")
    mock_extract.assert_called_once
()


@patch("readium.core.convert_url_to
_markdown")
def 
test_read_docs_url(mock_convert):
    """Test reading a URL 
directly"""
    # Setup mock
    mock_convert.return_value = (
        "Test Document",
        "# Test Document\n\nThis is
test content.",
    )

    # Setup reader
    reader = 
Readium(ReadConfig(debug=True))

    # Test URL processing
    summary, tree, content = 
reader.read_docs("https://example.c
om/documentation")

    # Assertions
    assert "URL processed: 
https://example.com/documentation" 
in summary
    assert "Title: Test Document" 
in summary
    assert "Documentation 
Structure:" in tree
    assert "documentation.md" in 
tree
    assert "# Test Document" in 
content
    assert "This is test content." 
in content


@patch("readium.core.convert_url_to
_markdown")
def 
test_read_docs_url_with_output(mock
_convert, tmp_path):
    """Test reading a URL with 
output file"""
    # Setup mock
    mock_convert.return_value = 
("Test Document", "# Test 
Document\n\nContent.")

    # Setup reader with split 
output
    output_dir = tmp_path / 
"output"
    reader = 
Readium(ReadConfig(debug=True))
    reader.split_output_dir = 
str(output_dir)

    # Test URL processing
    summary, tree, content = 
reader.read_docs("https://example.c
om/page.html")

    # Assertions
    assert "Split files output 
directory:" in summary
    assert 
os.path.exists(output_dir)

    # Check if at least one file 
was created
    files = 
list(output_dir.glob("*.txt"))
    assert len(files) > 0

    # Check content of first file
    with open(files[0], "r", 
encoding="utf-8") as f:
        file_content = f.read()
        assert "Original Path:" in 
file_content
        assert "# Test Document" in
file_content


# Check if trafilatura is installed
try:
    import trafilatura

    trafilatura_installed = True
except ImportError:
    trafilatura_installed = False


@pytest.mark.skipif(not 
trafilatura_installed, 
reason="Trafilatura not installed")
@patch("trafilatura.fetch_url")
def 
test_convert_url_error_handling(moc
k_fetch):
    """Test error handling when 
fetching URL fails"""
    # Setup mock to return None 
(failed download)
    mock_fetch.return_value = None

    # Import locally to avoid 
errors when trafilatura isn't 
installed
    from readium.core import 
convert_url_to_markdown

    # Test with invalid URL
    with pytest.raises(ValueError) 
as excinfo:
        convert_url_to_markdown("ht
tps://example.com/nonexistent")

    assert "Failed to download 
content" in str(excinfo.value)


def test_cli_url_processing():
    """Test CLI with URL 
processing"""
    import os

    from click.testing import 
CliRunner

    from readium.cli import main

    # Patch convert_url_to_markdown
to avoid actual network requests
    with 
patch("readium.core.convert_url_to_
markdown") as mock_convert:
        mock_convert.return_value =
("Test Title", "# Test Content")

        runner = CliRunner()
        with 
runner.isolated_filesystem():
            output_file = "docs.md"
            result = runner.invoke(
                main,
                [
                    "https://exampl
e.com/docs",
                    "--output",
                    output_file,
                    "--url-mode",
                    "clean",
                ],
            )

            # Verify successful 
execution
            assert result.exit_code
== 0

            # Verify that the file 
was created successfully
            assert f"Results saved 
to {output_file}" in result.output
            assert 
os.path.exists(output_file)

            # Verify the content of
the file
            with open(output_file, 
"r") as f:
                content = f.read()
                # Verify that the 
file content includes some of the 
expected content
                assert "# Test 
Content" in content


===================================
=============
File: 
tests/test_extension_exclusion.py
===================================
=============
import os
import tempfile
from pathlib import Path
from unittest.mock import patch

import pytest
from click.testing import CliRunner

from readium.cli import main
from readium.config import 
ReadConfig
from readium.core import Readium


@pytest.fixture
def temp_dir_with_files():
    """Create a temporary directory
with test files of various 
extensions"""
    with 
tempfile.TemporaryDirectory() as 
tmp_dir:
        path = Path(tmp_dir)
        # Create test files with 
different extensions
        files = {
            "doc1.md": "# Test 
Markdown",
            "doc2.txt": "Plain text
file",
            "code.py": "def test():
pass",
            "config.json": '{"key":
"value"}',
            "data.yml": "key: 
value",
            "styles.css": "body { 
color: black; }",
        }
        for name, content in 
files.items():
            file_path = path / name
            file_path.write_text(co
ntent)
        yield path


def 
test_exclude_extensions_basic(temp_
dir_with_files):
    """Test basic exclusion of a 
single file extension"""
    config = 
ReadConfig(exclude_extensions={".js
on"})
    reader = Readium(config)
    summary, tree, content = 
reader.read_docs(temp_dir_with_file
s)
    assert "Files processed:" in 
summary
    assert "doc1.md" in tree
    assert "code.py" in tree
    assert "config.json" not in 
tree
    assert "# Test Markdown" in 
content
    assert "def test():" in content
    assert '"key": "value"' not in 
content


def 
test_exclude_extensions_multiple(te
mp_dir_with_files):
    """Test exclusion of multiple 
file extensions"""
    config = 
ReadConfig(exclude_extensions={".js
on", ".yml"})
    reader = Readium(config)
    summary, tree, content = 
reader.read_docs(temp_dir_with_file
s)
    assert "Files processed:" in 
summary
    assert "doc1.md" in tree
    assert "code.py" in tree
    assert "config.json" not in 
tree
    assert "data.yml" not in tree
    # .css is not in default 
include_extensions, so it should 
not be in tree


def 
test_exclude_and_include_extensions
(temp_dir_with_files):
    """Test interaction between 
include and exclude extensions"""
    config = ReadConfig(
        include_extensions={".md", 
".json"}, 
exclude_extensions={".json"}
    )
    reader = Readium(config)
    summary, tree, content = 
reader.read_docs(temp_dir_with_file
s)
    assert "Files processed:" in 
summary
    assert "doc1.md" in tree
    assert "code.py" not in tree
    assert "config.json" not in 
tree
    assert "data.yml" not in tree
    assert "styles.css" not in tree
    assert "# Test Markdown" in 
content


def 
test_case_insensitive_extension_mat
ching(temp_dir_with_files):
    """Test that extension 
exclusion is case-insensitive"""
    uppercase_file = 
temp_dir_with_files / "test.JSON"
    uppercase_file.write_text('{"up
percase": true}')
    config = 
ReadConfig(exclude_extensions={".js
on"})
    reader = Readium(config)
    summary, tree, content = 
reader.read_docs(temp_dir_with_file
s)
    assert "config.json" not in 
tree
    assert "test.JSON" not in tree


def 
test_cli_exclude_extensions(temp_di
r_with_files):
    """Test CLI interface with 
exclude-ext option"""
    runner = CliRunner()
    result = runner.invoke(
        main,
        [
            str(temp_dir_with_files
),
            "--exclude-ext",
            ".json",
            "--exclude-ext",
            ".yml",
            "--debug",
        ],
        catch_exceptions=False,
    )
    assert result.exit_code == 0
    # Extract the "Tree" section 
from output for assertions
    tree_start = 
result.output.find("Tree:")
    content_start = 
result.output.find("Content:")
    tree_section = (
        result.output
        if tree_start != -1 and 
content_start != -1
        else result.output
    )
    assert "doc1.md" in 
tree_section
    assert "code.py" in 
tree_section
    assert "config.json" not in 
tree_section
    assert "data.yml" not in 
tree_section


@patch("readium.core.clone_reposito
ry")
def 
test_exclude_extensions_with_git(mo
ck_clone, temp_dir_with_files):
    """Test extension exclusion 
with git repositories"""
    mock_clone.side_effect = lambda
url, target_dir, branch=None: None
    config = 
ReadConfig(exclude_extensions={".js
on"})
    reader = Readium(config)
    with patch.object(reader, 
"_process_directory") as 
mock_process:
        mock_process.return_value =
(
            "Summary",
            "Tree without 
config.json",
            "Content without JSON",
        )
        summary, tree, content = 
reader.read_docs("https://github.co
m/fake/repo.git")
        mock_process.assert_called_
once()
        assert 
reader.config.exclude_extensions ==
{".json"}


def 
test_exclude_all_extensions(temp_di
r_with_files):
    """Test excluding all file 
extensions to ensure no files are 
processed"""
    all_extensions = {
        os.path.splitext(f)[1].lowe
r()
        for f in 
os.listdir(temp_dir_with_files)
        if "." in f
    }
    config = 
ReadConfig(exclude_extensions=all_e
xtensions)
    reader = Readium(config)
    summary, tree, content = 
reader.read_docs(temp_dir_with_file
s)
    assert "Files processed: 0" in 
summary
    assert "Documentation 
Structure:" in tree
    assert len(content.strip()) == 
0


===================================
=============
File: tests/test_readium.py
===================================
=============
import os
import tempfile
from pathlib import Path
from unittest.mock import Mock, 
patch

import pytest
from click.testing import CliRunner
from pypdf import PdfWriter

from readium import ReadConfig, 
Readium, main
from readium.core import 
clone_repository, is_git_url

# Test data setup
TEST_CONTENT = """# Test Document
This is a test document for 
Readium.
"""


@pytest.fixture
def temp_dir():
    with 
tempfile.TemporaryDirectory() as 
tmp_dir:
        yield Path(tmp_dir)


@pytest.fixture
def sample_files(temp_dir):
    # Create test files with 
different extensions
    files = {
        "doc1.md": "# Test 
Markdown",
        "doc2.txt": "Plain text 
file",
        "code.py": "def test(): 
pass",
        "large.md": "x" * (5 * 1024
* 1024 + 1),  # Exceeds default 
size limit
        "config.json": '{"key": 
"value"}',
        ".hidden": "hidden file",
        "document.pdf": "PDF 
content",  # Para test de 
MarkItDown
    }

    for name, content in 
files.items():
        file_path = temp_dir / name
        file_path.write_text(conten
t)

    # Create test directories
    (temp_dir / 
"node_modules").mkdir()
    # Crear el archivo test.js 
dentro de node_modules
    (temp_dir / "node_modules" / 
"test.js").write_text('console.log(
"test")')

    (temp_dir / "docs").mkdir()
    (temp_dir / "docs" / 
"guide.md").write_text("# Guide")

    return temp_dir


@pytest.fixture
def sample_pdf(sample_files):
    """Create a real PDF file for 
testing"""
    # Crear un PDF simple
    writer = PdfWriter()
    # AÃ±adir una pÃ¡gina en blanco
    writer.add_blank_page(width=72,
height=72)

    pdf_path = sample_files / 
"document.pdf"
    with open(pdf_path, "wb") as 
output_file:
        writer.write(output_file)

    return pdf_path


def test_read_config_defaults():
    """Test ReadConfig 
initialization with default 
values"""
    config = ReadConfig()
    assert config.max_file_size == 
5 * 1024 * 1024  # 5MB
    assert ".git" in 
config.exclude_dirs
    assert ".md" in 
config.include_extensions
    assert config.target_dir is 
None
    assert not 
config.use_markitdown
    assert ".pdf" in 
config.markitdown_extensions
    assert not config.debug


def test_read_config_custom():
    """Test ReadConfig 
initialization with custom 
values"""
    config = ReadConfig(
        max_file_size=1024, 
target_dir="docs", 
use_markitdown=True, debug=True
    )
    assert config.max_file_size == 
1024
    assert config.target_dir == 
"docs"
    assert config.use_markitdown
    assert config.debug


def test_is_git_url():
    """Test git URL detection"""
    assert 
is_git_url("https://github.com/user
/repo.git")
    assert 
is_git_url("https://github.com/user
/repo")
    assert 
is_git_url("https://gitlab.com/user
/repo")
    assert not 
is_git_url("http://example.com")
    assert not 
is_git_url("/local/path")


@patch("subprocess.run")
def test_clone_repository(mock_run,
temp_dir):
    """Test repository cloning 
functionality"""
    url = 
"https://github.com/user/repo.git"
    clone_repository(url, 
str(temp_dir))
    mock_run.assert_called_once()
    assert "--depth=1" in 
mock_run.call_args[0][0]


def test_readium_init():
    """Test Readium 
initialization"""
    reader = Readium()
    assert reader.config is not 
None
    assert reader.markitdown is 
None

    reader_with_markitdown = 
Readium(ReadConfig(use_markitdown=T
rue))
    assert 
reader_with_markitdown.markitdown 
is not None


def 
test_should_process_file(sample_fil
es):
    """Test file processing 
criteria"""
    reader = Readium()

    # Should process normal 
markdown file
    assert 
reader.should_process_file(sample_f
iles / "doc1.md")

    # Should not process files in 
excluded directories
    assert not 
reader.should_process_file(sample_f
iles / "node_modules" / "test.js")

    # Should not process files 
exceeding size limit
    assert not 
reader.should_process_file(sample_f
iles / "large.md")

    # Should process files with 
allowed extensions
    assert 
reader.should_process_file(sample_f
iles / "code.py")


def 
test_read_docs_local(sample_files):
    """Test reading documentation 
from local directory"""
    reader = Readium()
    summary, tree, content = 
reader.read_docs(sample_files)

    assert "Files processed:" in 
summary
    assert "Documentation 
Structure:" in tree
    assert "# Test Markdown" in 
content
    assert "Plain text file" in 
content


def 
test_read_docs_with_target_dir(samp
le_files):
    """Test reading documentation 
with target directory specified"""
    config = 
ReadConfig(target_dir="docs")
    reader = Readium(config)
    summary, tree, content = 
reader.read_docs(sample_files)

    assert "Target directory: docs"
in summary
    assert "guide.md" in tree
    assert "# Guide" in content
    assert "doc1.md" not in content
# Should not include files outside 
target dir


@patch("readium.core.clone_reposito
ry")
def test_read_docs_git(mock_clone, 
temp_dir):
    """Test reading documentation 
from git repository"""
    # Configurar el mock para que 
lance una excepciÃ³n
    mock_clone.side_effect = 
ValueError("Failed to clone 
repository")
    reader = Readium()

    with pytest.raises(ValueError):
        reader.read_docs("https://g
ithub.com/fake/repo.git")

    mock_clone.assert_called_once()


@patch("readium.core.MarkItDown")  
# Cambiamos el path del patch
def 
test_read_docs_with_markitdown(mock
_markitdown, sample_files, 
sample_pdf):
    """Test reading documentation 
with MarkItDown integration"""
    # Configurar el mock
    mock_instance = Mock()
    mock_instance.convert.return_va
lue = Mock(text_content="Converted 
content")
    mock_markitdown.return_value = 
mock_instance

    # AÃ±adimos algunos logs para 
debug
    print("\nDebug: Mock setup 
complete")

    # Configurar Readium con 
MarkItDown solo para PDFs
    config = ReadConfig(
        use_markitdown=True,
        markitdown_extensions={".pd
f"},
        include_extensions=set(),  
# No procesar otros tipos de 
archivo
        debug=True,  # Activar logs
de debug
    )
    reader = Readium(config)
    print(f"Debug: Reader 
markitdown instance: 
{reader.markitdown}")

    summary, tree, content = 
reader.read_docs(sample_files)
    print(f"Debug: Mock convert 
called: 
{mock_instance.convert.called}")
    print(f"Debug: Mock convert 
call args: 
{mock_instance.convert.call_args_li
st}")

    assert "Using MarkItDown for 
compatible files" in summary
    assert 
mock_instance.convert.called
    assert str(sample_pdf) in [
        args[0] for args, _ in 
mock_instance.convert.call_args_lis
t
    ]
    assert "Converted content" in 
content


def 
test_markitdown_integration_real(sa
mple_pdf, sample_files):
    """Test real integration with 
MarkItDown using an actual PDF file
(no mocks)"""
    config = ReadConfig(
        use_markitdown=True,
        markitdown_extensions={".pd
f"},
        include_extensions=set(),  
# Solo procesar PDFs
        debug=True,
    )
    reader = Readium(config)
    summary, tree, content = 
reader.read_docs(sample_files)
    # El PDF debe aparecer en el 
Ã¡rbol y el contenido debe contener 
alguna marca de conversiÃ³n
    assert "document.pdf" in tree
    assert "Using MarkItDown" in 
summary or "MarkItDown" in content 
or "PDF" in content


# Integration tests


def 
test_full_directory_scan(sample_fil
es):
    """Integration test for full 
directory scanning"""
    config = ReadConfig(
        max_file_size=1024 * 1024, 
# 1MB
        exclude_dirs={"node_modules
"},
        include_extensions={".md", 
".txt", ".py"},
        debug=True,
    )
    reader = Readium(config)
    summary, tree, content = 
reader.read_docs(sample_files)

    # Verify summary
    assert "Path analyzed:" in 
summary
    assert "Files processed:" in 
summary

    # Verify tree structure
    assert "Documentation 
Structure:" in tree
    assert "doc1.md" in tree
    assert "doc2.txt" in tree
    assert "code.py" in tree

    # Verify content
    assert "# Test Markdown" in 
content
    assert "Plain text file" in 
content
    assert "def test():" in content


def test_real_repository_scan():
    """Integration test using the 
real Readium repository"""
    config = ReadConfig(
        debug=True,
        exclude_dirs={"node_modules
", "dist", "build"},  # Common 
exclusions
    )
    reader = Readium(config)
    url = 
"https://github.com/pablotoledo/Rea
dium.git"

    summary, tree, content = 
reader.read_docs(url)

    # Verify basic content from 
main branch
    assert "README.md" in tree
    assert "# ðŸ“š Readium" in 
content
    assert "Path analyzed:" in 
summary


def 
test_real_repository_specific_branc
h():
    """Integration test using a 
specific branch from Readium 
repository"""
    config = ReadConfig(debug=True)
    reader = Readium(config)
    url = 
"https://github.com/pablotoledo/Rea
dium.git"
    branch = "fix/issue-1"

    summary, tree, content = 
reader.read_docs(url, 
branch=branch)

    # Verify branch information 
appears in summary
    assert f"Git branch: {branch}" 
in summary

    # Verify we can access basic 
content from the branch
    assert "README.md" in tree
    assert "pyproject.toml" in tree

    # Verify content contains 
expected files
    assert "Documentation 
Structure:" in tree
    assert "# ðŸ“š Readium" in 
content


def 
test_real_repository_branch_content
_comparison():
    """Test to compare content 
between main and specific branch"""
    reader = 
Readium(ReadConfig(debug=True))
    url = 
"https://github.com/pablotoledo/Rea
dium.git"

    # Get content from main branch
    main_summary, main_tree, 
main_content = 
reader.read_docs(url)

    # Get content from specific 
branch
    branch_summary, branch_tree, 
branch_content = reader.read_docs(
        url, branch="fix/issue-1"
    )

    # Verify we can get content 
from both branches
    assert "README.md" in main_tree
    assert "README.md" in 
branch_tree

    # Verify branch information 
only appears in branch summary
    assert "Git branch: 
fix/issue-1" in branch_summary
    assert "Git branch: " not in 
main_summary


def 
test_cli_with_real_repository():
    """Test CLI integration with 
real repository"""
    runner = CliRunner()
    with 
runner.isolated_filesystem():
        result = runner.invoke(
            main,
            [
                "https://github.com
/pablotoledo/Readium.git",
                "-b",
                "fix/issue-1",
                "--debug",
            ],
        )

        # Verify successful 
execution
        assert result.exit_code == 
0
        assert "Git branch: 
fix/issue-1" in result.output
        assert "README.md" in 
result.output


===================================
=============
File: tests/unit/test_cli.py
===================================
=============
from click.testing import CliRunner

from readium.cli import main


def 
test_help_includes_output_option():
    runner = CliRunner()
    result = runner.invoke(main, 
["--help"])
    assert "-o, --output" in 
result.output
    assert "Output file path" in 
result.output
    assert "readium 
/path/to/directory -o output.md" in
result.output  # Updated line


def test_help_includes_examples():
    runner = CliRunner()
    result = runner.invoke(main, 
["--help"])
    assert "Examples:" in 
result.output
    assert "Process a local 
directory" in result.output


def 
test_exclude_dir_single(monkeypatch
):
    """Test using -x once passes 
the value to the config."""
    runner = CliRunner()
    # Patch Readium.read_docs to 
avoid actual processing
    monkeypatch.setattr(
        "readium.core.Readium.read_
docs",
        lambda self, path, 
branch=None: ("summary", "tree", 
"content"),
    )
    result = runner.invoke(main, 
[".", "-x", "dir1"])
    assert result.exit_code == 0
    # No error should occur, and 
the CLI should run


def 
test_exclude_dir_multiple(monkeypat
ch):
    """Test using -x multiple times
passes all values to the config."""
    runner = CliRunner()
    monkeypatch.setattr(
        "readium.core.Readium.read_
docs",
        lambda self, path, 
branch=None: ("summary", "tree", 
"content"),
    )
    result = runner.invoke(main, 
[".", "-x", "dir1", "-x", "dir2"])
    assert result.exit_code == 0


def 
test_exclude_dir_duplicates(monkeyp
atch):
    """Test using -x with duplicate
values does not cause error."""
    runner = CliRunner()
    monkeypatch.setattr(
        "readium.core.Readium.read_
docs",
        lambda self, path, 
branch=None: ("summary", "tree", 
"content"),
    )
    result = runner.invoke(main, 
[".", "-x", "dir1", "-x", "dir1"])
    assert result.exit_code == 0


def 
test_exclude_dir_empty_value(monkey
patch):
    """Test using -x with an empty 
value should fail or warn."""
    runner = CliRunner()
    monkeypatch.setattr(
        "readium.core.Readium.read_
docs",
        lambda self, path, 
branch=None: ("summary", "tree", 
"content"),
    )
    result = runner.invoke(main, 
[".", "-x", ""])
    # Should fail or print an error
message
    assert result.exit_code != 0 or
"exclude-dir" in 
result.output.lower()


===================================
=============
File: 
tests/unit/utils/test_error_handlin
g.py
===================================
=============
import io

from rich.console import Console

from readium.utils.error_handling 
import print_error


def test_print_error_normal():
    console = 
Console(file=io.StringIO(), 
force_terminal=True)
    print_error(console, "Normal 
error")
    assert "Normal error" in 
console.file.getvalue()


def test_print_error_with_markup():
    console = 
Console(file=io.StringIO(), 
force_terminal=True)
    print_error(console, "Error 
with ")
    output = 
console.file.getvalue()
    assert "Error:" in output
    assert "Error with" in output


def 
test_print_error_with_rich_markup()
:
    console = 
Console(file=io.StringIO(), 
force_terminal=True)
    print_error(console, 
"Formatted")
    output = 
console.file.getvalue()
    assert "Error:" in output
    assert "Formatted" in output


===================================
=============
File: 
.devcontainer/devcontainer.json
===================================
=============
{
    "name": "Readium Development",
    "dockerFile": "Dockerfile",
    "build": {
        "context": "..",
        "args": {
            "VARIANT": "3.10"
        }
    },

    "customizations": {
        "vscode": {
            "settings": {
                "python.defaultInte
rpreterPath": 
"/usr/local/bin/python",
                "python.formatting.
provider": "black",
                "python.linting.ena
bled": true,
                "python.linting.myp
yEnabled": true
            },
            "extensions": [
                "ms-python.python",
                "ms-vscode.cpptools
",
                "clemenspeters.form
at-json",
                "davidanson.vscode-
markdownlint",
                "george-alisson.htm
l-preview-vscode",
                "github.copilot",
                "github.copilot-cha
t",
                "ms-dotnettools.vsc
ode-dotnet-runtime",
                "ms-python.debugpy"
,
                "ms-python.vscode-p
ylance",
                "ms-toolsai.jupyter
",
                "ms-toolsai.jupyter
-keymap",
                "ms-toolsai.jupyter
-renderers",
                "ms-toolsai.vscode-
ai",
                "ms-toolsai.vscode-
ai-remote",
                "ms-toolsai.vscode-
jupyter-cell-tags",
                "ms-toolsai.vscode-
jupyter-slideshow",
                "ms-vscode.powershe
ll",
                "rangav.vscode-thun
der-client",
                "rapidapi.vscode-ra
pidapi-client",
                "rapidapi.vscode-se
rvices",
                "waderyan.gitblame"
,
                "hediet.vscode-draw
io",
                "pomdtr.excalidraw-
editor"
            ]
        }
    },

    "postCreateCommand": "pip 
install --user -e '.' && pip 
install hatch pre-commit pytest 
mypy black isort pytest-mock",

    "remoteUser": "vscode",

    "features": {
        "ghcr.io/devcontainers/feat
ures/git:1": {},
        "ghcr.io/devcontainers/feat
ures/github-cli:1": {},
        "ghcr.io/devcontainers-cont
rib/features/hatch:2": {}
    }
}


===================================
=============
File: .github/workflows/publish.yml
===================================
=============
name: Publish to PyPI

on:
  release:
    types: 

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: 
actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Poetry
        uses: 
snok/install-poetry@v1
        with:
          version: latest
          virtualenvs-create: true
          virtualenvs-in-project: 
true

      - name: Install dependencies
        run: |
          poetry install

      - name: Build and publish
        env:
          POETRY_PYPI_TOKEN_PYPI: 
${{ secrets.PYPI_API_TOKEN }}
        run: |
          poetry build
          poetry publish


===================================
=============
File: .github/workflows/test.yml
===================================
=============
name: Tests
# act -j test 
--container-architecture 
linux/amd64 -P 
ubuntu-latest=catthehacker/ubuntu:a
ct-latest

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10", 
"3.11", "3.12"]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ 
matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ 
matrix.python-version }}

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: 
true

    - name: Install dependencies
      run: |
        poetry install --with dev

    - name: Run tests
      run: |
        poetry run pytest -p 
no:warnings


===================================
=============
File: src/readium/config.py
===================================
=============
from dataclasses import dataclass, 
field
from typing import Literal, 
Optional, Set, Tuple, Union  # Add 
Tuple and Union for function return
type

DEFAULT_EXCLUDE_DIRS = {
    ".git",
    "node_modules",
    "__pycache__",
    "assets",
    "img",
    "images",
    "dist",
    "build",
    ".next",
    ".vscode",
    ".idea",
    "bin",
    "obj",
    "target",
    "out",
    ".venv",
    "venv",
    ".gradle",
    ".pytest_cache",
    ".mypy_cache",
    "htmlcov",
    "coverage",
    ".vs",
    "Pods",
}

DEFAULT_EXCLUDE_FILES = {
    ".pyc",
    ".pyo",
    ".pyd",
    ".DS_Store",
    ".gitignore",
    ".env",
    "Thumbs.db",
    "desktop.ini",
    "npm-debug.log",
    "yarn-error.log",
    "pnpm-debug.log",
    "*.log",
    "*.lock",
}

DEFAULT_INCLUDE_EXTENSIONS = {
    ".md",
    ".mdx",
    ".txt",
    ".yml",
    ".yaml",
    ".rst",
    ".py",
    ".js",
    ".ts",
    ".jsx",
    ".tsx",
    ".java",
    ".c",
    ".cpp",
    ".h",
    ".hpp",
    ".rs",
    ".go",
    ".rb",
    ".php",
    ".sh",
    ".swift",
    ".kt",
    ".kts",
    ".scala",
    ".pl",
    ".pm",
    ".r",
    ".jl",
    ".lua",
    ".dart",
    ".m",
    ".mm",
    ".cs",
    ".vb",
    ".fs",
    ".asm",
    ".s",
    ".v",
    ".sv",
    ".vhd",
    ".vhdl",
    ".clj",
    ".cljs",
    ".groovy",
    ".hs",
    ".erl",
    ".ex",
    ".exs",
    ".ml",
    ".mli",
    ".nim",
    ".pas",
    ".pp",
    ".sql",
    ".adb",
    ".ads",
    ".ada",
    ".d",
    ".cr",
    ".nim",
    ".rkt",
    ".scm",
    ".ss",
    ".tcl",
    ".tk",
    ".bat",
    ".cmd",
    ".ps1",
    ".psm1",
    ".psd1",
    ".bas",
    ".cls",
    ".frm",
    ".ctl",
    ".vbproj",
    ".csproj",
    ".fsproj",
    ".vcxproj",
    ".xcodeproj",
    ".xcworkspace",
    ".sln",
    ".makefile",
    ".mk",
    ".cmake",
    ".gradle",
    ".pom",
    ".build",
    ".proj",
    ".toml",
    ".ini",
    ".cfg",
    ".conf",
    ".json",
    ".xml",
    ".ipynb",
}

MARKITDOWN_EXTENSIONS = {
    ".pdf",
    ".docx",
    ".xlsx",
    ".xls",
    ".pptx",
    ".html",
    ".htm",
    ".msg",
}

# Add a new constant for URL 
processing modes
URL_MODES = Literal["full", 
"clean"]


@dataclass
class ReadConfig:
    """Configuration for document 
reading

    Attributes
    ----------
    exclude_extensions : Set
        File extensions to exclude 
from processing (takes precedence 
over include_extensions).
    """

    max_file_size: int = 5 * 1024 *
1024  # 5MB default
    exclude_dirs: Set = 
field(default_factory=lambda: 
DEFAULT_EXCLUDE_DIRS.copy())
    exclude_files: Set = field(
        default_factory=lambda: 
DEFAULT_EXCLUDE_FILES.copy()
    )
    include_extensions: Set = 
field(
        default_factory=lambda: 
DEFAULT_INCLUDE_EXTENSIONS.copy()
    )
    exclude_extensions: Set = 
field(default_factory=set)
    target_dir: Optional = None
    use_markitdown: bool = False
    markitdown_extensions: 
Optional[Set] = field(
        default_factory=lambda: 
MARKITDOWN_EXTENSIONS.copy()
    )
    debug: bool = False
    url_mode: URL_MODES = "clean"  
# URL processing mode (new)
    include_comments: bool = False 
# Include web page comments (new)
    include_tables: bool = True  # 
Include tables from web pages (new)
    include_images: bool = True  # 
Include image references (new)
    include_links: bool = True  # 
Include links (new)
    show_token_tree: bool = False  
# Show token tree (new)
    token_calculation: 
Literal["simple", "tiktoken"] = 
"simple"  # Token calculation mode 
(new)


def convert_url_to_markdown(url: 
str, config: ReadConfig) -> Tuple:
    """
    Convert a URL to Markdown using
trafilatura.

    Parameters
    ----------
    url : str
        URL to convert.
    config : ReadConfig
        Configuration for 
processing.

    Returns
    -------
    Tuple:
        Extracted title, content in
Markdown format.
    """
    import trafilatura
    from trafilatura.settings 
import use_config

    try:
        # Configure trafilatura for
Markdown output
        trafilatura_config = 
use_config()
        trafilatura_config.set("DEF
AULT", "output_format", "markdown")

        # Adjust extraction 
settings based on URL mode
        if config.url_mode == 
"full":
            # Disable aggressive 
filtering
            trafilatura_config.set(
"DEFAULT", "extraction_timeout", 
"30")
            trafilatura_config.set(
"DEFAULT", "min_extracted_size", 
"10")
            trafilatura_config.set(
                "EXTRACTION",
                "list_tags",
                "p, blockquote, q, 
dl, ul, ol, h1, h2, h3, h4, h5, h6,
div, section, article",
            )

        # Download and extract 
content
        downloaded = 
trafilatura.fetch_url(url)
        if not downloaded:
            raise 
ValueError(f"Failed to download 
content from {url}")

        # Extract metadata and 
content
        metadata = 
trafilatura.extract_metadata(downlo
aded)
        title = metadata.title if 
metadata and metadata.title else 
"Untitled"

        # Extract content as 
Markdown
        markdown = 
trafilatura.extract(
            downloaded,
            output_format="markdown
",
            include_tables=config.i
nclude_tables,
            include_images=config.i
nclude_images,
            include_links=config.in
clude_links,
            include_comments=config
.include_comments,
            config=trafilatura_conf
ig,
        )

        if not markdown:
            raise 
ValueError(f"Failed to extract 
content from {url}")

        return title, markdown

    except Exception as e:
        raise ValueError(f"Error 
converting URL to Markdown: 
{str(e)}")


===================================
=============
File: src/readium/__init__.py
===================================
=============
from .cli import main
from .core import ReadConfig, 
Readium
from .utils.error_handling import 
print_error

__all__ = ["ReadConfig", "Readium",
"print_error", "main"]


===================================
=============
File: src/readium/core.py
===================================
=============
import os
import subprocess
import tempfile
import urllib.parse
import uuid
from dataclasses import dataclass, 
field
from pathlib import Path
from typing import Dict, List, 
Optional, Set, Tuple, Union

from markitdown import 
FileConversionException, 
MarkItDown, 
UnsupportedFormatException

from .config import (
    DEFAULT_EXCLUDE_DIRS,
    DEFAULT_EXCLUDE_FILES,
    DEFAULT_INCLUDE_EXTENSIONS,
    MARKITDOWN_EXTENSIONS,
    ReadConfig,
)


def is_git_url(url: str) -> bool:
    """Check if the given string is
a git URL"""
    if not 
url.startswith(("http://", 
"https://")):
        return False

    # Detect Git-specific URLs
    if url.endswith(".git"):
        return True

    # Detect GitHub/GitLab style 
paths
    if "github.com/" in url or 
"gitlab.com/" in url:
        parts = url.split("/")
        # Basic user/repo format 
(at least 4 parts)
        if len(parts) >= 4:
            return True

    return False


def is_url(url: str) -> bool:
    """Check if a string is a valid
URL (but not a git URL)"""
    try:
        result = 
urllib.parse.urlparse(url)
        # It is an HTTP/HTTPS URL 
but NOT a git URL
        is_valid_url = all() and 
result.scheme in (
            "http",
            "https",
        )
        return is_valid_url and not
is_git_url(url)
    except ValueError:
        return False


def convert_url_to_markdown(
    url: str, config: 
Optional[ReadConfig] = None
) -> Tuple:
    """
    Convert a URL to Markdown using
trafilatura

    Parameters
    ----------
    url : str
        URL to convert.
    config : Optional[ReadConfig]
        Configuration for 
processing, defaults to None

    Returns
    -------
    Tuple:
        Extracted title, content in
Markdown format.
    """
    if config is None:
        config = ReadConfig()

    try:
        # Attempt to import 
trafilatura here to handle import 
errors
        import trafilatura
        from trafilatura.settings 
import use_config

        # Configure trafilatura for
Markdown output
        trafilatura_config = 
use_config()
        trafilatura_config.set("DEF
AULT", "output_format", "markdown")

        # Adjust extraction 
settings based on URL mode
        if config.url_mode == 
"full":
            # Disable aggressive 
filtering
            trafilatura_config.set(
"DEFAULT", "extraction_timeout", 
"30")
            trafilatura_config.set(
"DEFAULT", "min_extracted_size", 
"10")
            trafilatura_config.set(
                "EXTRACTION",
                "list_tags",
                "p, blockquote, q, 
dl, ul, ol, h1, h2, h3, h4, h5, h6,
div, section, article",
            )

        # Download and extract 
content
        downloaded = 
trafilatura.fetch_url(url)
        if not downloaded:
            raise 
ValueError(f"Failed to download 
content from {url}")

        # Extract metadata and 
content
        metadata = 
trafilatura.extract_metadata(downlo
aded)
        title = metadata.title if 
metadata and metadata.title else 
"Untitled"

        # Extract content as 
Markdown
        markdown = 
trafilatura.extract(
            downloaded,
            output_format="markdown
",
            include_tables=config.i
nclude_tables,
            include_images=config.i
nclude_images,
            include_links=config.in
clude_links,
            include_comments=config
.include_comments,
            config=trafilatura_conf
ig,
        )

        if not markdown:
            raise 
ValueError(f"Failed to extract 
content from {url}")

        return title, markdown

    except ImportError:
        # If trafilatura is not 
installed, return an error message
        print(
            "Warning: Trafilatura 
is not installed. URL to Markdown 
conversion is disabled."
        )
        # Return generic error 
content
        return (
            "Error",
            f"# Error\n\nUnable to 
convert URL: {url}. The required 
package 'trafilatura' is not 
installed.",
        )
    except Exception as e:
        raise ValueError(f"Error 
converting URL to Markdown: 
{str(e)}")


def clone_repository(url: str, 
target_dir: str, branch: Optional =
None) -> None:
    """Clone a git repository to 
the target directory

    Parameters
    ----------
    url : str
        Repository URL
    target_dir : str
        Target directory for 
cloning
    branch : Optional
        Specific branch to clone 
(default: None, uses default 
branch)
    """
    try:
        # Base command
        cmd = ["git", "clone", 
"--depth=1"]

        # Add branch specification 
if provided
        if branch:
            cmd.extend(["-b", 
branch])

        # If the URL contains '@', 
it is likely to have a token
        if "@" in url:
            # Extract the token and
reconstruct the URL
            parts = url.split("@")
            token = 
parts[0].split("://")[-1]
            base_url = 
"://".join(parts[0].split("://")[:-
1])
            repo_url = 
f"{base_url}://{parts[1]}"

            # Log for debugging 
(hiding the full token)
            token_preview = 
f"{token[:4]}...{token[-4:]}" if 
len(token) > 8 else "****"
            print(f"DEBUG: 
Attempting to clone with token: 
{token_preview}")
            if branch:
                print(f"DEBUG: 
Using branch: {branch}")

            # Use the token as a 
password with an empty username
            env = os.environ.copy()
            env["GIT_ASKPASS"] = 
"echo"
            env["GIT_USERNAME"] = 
""
            env["GIT_PASSWORD"] = 
token

            cmd.extend()
            subprocess.run(cmd, 
check=True, capture_output=True, 
env=env)
        else:
            cmd.extend()
            subprocess.run(cmd, 
check=True, capture_output=True)

    except 
subprocess.CalledProcessError as e:
        error_msg = 
e.stderr.decode()
        # Hide the token in the 
error message if present
        if "@" in url:
            parts = url.split("@")
            token = 
parts[0].split("://")[-1]
            error_msg = 
error_msg.replace(token, "****")
        raise ValueError(f"Failed 
to clone repository: {error_msg}")


class Readium:
    """Main class for reading 
documentation"""

    def __init__(self, config: 
Optional[ReadConfig] = None):
        self.config = config or 
ReadConfig()
        self.markitdown = 
MarkItDown() if 
self.config.use_markitdown else 
None
        self.branch: Optional = 
None
        self.split_output_dir: 
Optional = None

    def log_debug(self, msg: str) 
-> None:
        """Print debug messages if 
debug mode is enabled"""
        if self.config.debug:
            print(f"DEBUG: {msg}")

    def is_binary(self, file_path: 
Union) -> bool:
        """Check if a file is 
binary"""
        try:
            with open(file_path, 
"rb") as file:
                chunk = 
file.read(1024)
                return bool(
                    chunk.translate
(
                        None,
                        bytes([7, 
8, 9, 10, 12, 13, 27] + 
list(range(0x20, 0x100))),
                    )
                )
        except Exception:
            return True

    def should_process_file(self, 
file_path: Union) -> bool:
        """Determine if a file 
should be processed based on 
configuration"""
        path = Path(file_path)
        file_ext = 
os.path.splitext(str(path))[1].lowe
r()

        self.log_debug(f"Checking 
file: {path}")

        # First check if the file 
is in an excluded directory
        parts = path.parts
        for excluded_dir in 
self.config.exclude_dirs:
            if excluded_dir in 
parts:
                self.log_debug(
                    f"Excluding 
{path} due to being in excluded 
directory {excluded_dir}"
                )
                return False

        # Check exclude patterns - 
handle macOS @ suffix
        base_name = 
path.name.rstrip("@")
        if any(pattern in base_name
for pattern in 
self.config.exclude_files):
            self.log_debug(f"Exclud
ing {path} due to exclude 
patterns")
            return False

        # NEW: Check if the file 
extension is in the excluded 
extensions (case-insensitive)
        if file_ext in {ext.lower()
for ext in 
self.config.exclude_extensions}:
            self.log_debug(f"Exclud
ing {path} due to excluded 
extension {file_ext}")
            return False

        # Check size
        if 
self.config.max_file_size >= 0:
            try:
                file_size = 
path.stat().st_size
                if file_size > 
self.config.max_file_size:
                    self.log_debug(
                        f"Excluding
{path} due to size: {file_size} > 
{self.config.max_file_size}"
                    )
                    return False
            except 
FileNotFoundError:
                return False

        should_use_markitdown = (
            self.config.use_markitd
own
            and 
self.config.markitdown_extensions 
is not None
            and file_ext in 
self.config.markitdown_extensions
        )

        if should_use_markitdown:
            self.log_debug(f"Includ
ing {path} for markitdown 
processing")
            return True

        # If not using markitdown 
or file isn't compatible with 
markitdown,
        # check if it's in the 
included extensions
        if file_ext not in 
self.config.include_extensions:
            self.log_debug(f"Extens
ion {file_ext} not in supported 
extensions")
            return False

        # Check if binary only for 
non-markitdown files
        if not 
should_use_markitdown:
            is_bin = 
self.is_binary(path)
            if is_bin:
                self.log_debug(f"Ex
cluding {path} because it's 
binary")
                return False

        self.log_debug(f"Including 
{path} for processing")
        return True

    def estimate_tokens(self, text:
str) -> int:
        """
        Estimate the number of 
tokens in a text string.
        """
        if 
self.config.token_calculation == 
"tiktoken":
            try:
                import tiktoken
                encoding = 
tiktoken.get_encoding("cl100k_base"
)
                return 
len(encoding.encode(text))
            except ImportError:
                self.log_debug("tik
token not available, falling back 
to simple estimation")
                words = 
len(text.split())
                return int(words * 
0.75)
        else:
            words = 
len(text.split())
            return int(words * 
0.75)

    def generate_token_tree(self, 
files: list, base_path: Path) -> 
str:
        """
        Generate a token tree table
grouped by directory.
        """
        from rich.console import 
Console
        from rich.table import 
Table
        from collections import 
defaultdict
        import os
        console = Console()
        dir_files = 
defaultdict(list)
        dir_totals = 
defaultdict(int)
        total_tokens = 0
        console.print("Calculating 
tokens for files...")
        for idx, file_info in 
enumerate(files):
            path = 
file_info['path']
            content = 
file_info['content']
            tokens = 
self.estimate_tokens(content)
            dir_path = 
os.path.dirname(path)
            if not dir_path:
                dir_path = '.'
            dir_files.append({
                'filename': 
os.path.basename(path),
                'path': path,
                'tokens': tokens
            })
            dir_totals += tokens
            total_tokens += tokens
            if idx % 10 == 0:
                console.print(f"Pro
cessed {idx+1}/{len(files)} 
files...", end="\r")
        console.print(f"Processed 
{len(files)} files.")
        md_table = "# Directory 
Token Tree\n\n"
        md_table += "| Directory | 
Files | Token Count |\n"
        md_table += 
"|-----------|-------|------------|
\n"
        table = 
Table(title="Directory Token Tree")
        table.add_column("Directory
", style="cyan")
        table.add_column("Files", 
style="green")
        table.add_column("Token 
Count", style="yellow", 
justify="right")
        for dir_path in 
sorted(dir_files.keys()):
            files_in_dir = 
dir_files
            dir_token_count = 
dir_totals
            md_table += f"| 
**{dir_path}** | 
{len(files_in_dir)} | 
{dir_token_count:,} |\n"
            table.add_row(f"{dir_pa
th}", str(len(files_in_dir)), 
f"{dir_token_count:,}")
            for file_info in 
sorted(files_in_dir, key=lambda x: 
x['filename']):
                filename = 
file_info['filename']
                file_tokens = 
file_info['tokens']
                md_table += f"| â””â”€ 
{filename} | | {file_tokens:,} |\n"
                table.add_row(f"â””â”€ 
{filename}", "", 
f"{file_tokens:,}")
        md_table += f"\n**Total 
Files:** {len(files)}  \n"
        md_table += f"**Total 
Tokens:** {total_tokens:,}\n"
        console.print(table)
        console.print(f"Total 
Files: {len(files)}")
        console.print(f"Total 
Tokens: {total_tokens:,}")
        return md_table

    def read_docs(
        self, path: Union, branch: 
Optional = None
    ) -> Tuple:
        """
        Read documentation from a 
directory, git repository, or URL

        Parameters
        ----------
        path : Union
            Local path, git URL, or
web URL
        branch : Optional
            Specific branch to 
clone for git repositories 
(default: None)

        Returns
        -------
        Tuple:
            summary, tree 
structure, content
        """
        self.branch = branch

        # If it's a git URL, clone 
first
        if isinstance(path, str) 
and is_git_url(path):
            with 
tempfile.TemporaryDirectory() as 
temp_dir:
                try:
                    clone_repositor
y(path, temp_dir, branch)
                    return 
self._process_directory(Path(temp_d
ir), original_path=path)
                except Exception as
e:
                    raise 
ValueError(f"Error processing git 
repository: {str(e)}")
        # If it's a regular URL, 
process it
        elif isinstance(path, str) 
and is_url(path):
            try:
                self.log_debug(f"UR
L detected: {path}")

                # Extract title and
Markdown content
                title, 
markdown_content = 
convert_url_to_markdown(path, 
self.config)

                # Generate file 
name from the URL
                file_name = (
                    os.path.basenam
e(urllib.parse.urlparse(path).path)
 or "index.md"
                )
                if not 
file_name.endswith(".md"):
                    file_name += 
".md"

                # Generate result
                file_info = [
                    {"path": 
file_name, "content": 
markdown_content, "title": title}
                ]

                # Generate token 
tree if enabled
                token_tree = ""
                if 
self.config.show_token_tree:
                    self.log_debug(
"Generating token tree for URL 
content...")
                    token_tree = 
self.generate_token_tree(file_info,
Path(urllib.parse.urlparse(path).ne
tloc))

                # Write split files
if output directory is specified
                if 
self.split_output_dir:
                    self.write_spli
t_files(
                        file_info, 
Path(urllib.parse.urlparse(path).ne
tloc)
                    )

                # Generate tree 
structure
                tree = 
"Documentation Structure:\n"
                tree += f"â””â”€â”€ 
{file_name} (from {path})\n"

                # Generate content
                content = 
f"=================================
===============\n"
                content += f"File: 
{file_name}\n"
                content += 
f"Source: {path}\n"
                content += f"Title:
{title}\n"
                content += 
f"=================================
===============\n\n"
                content += 
markdown_content

                # Append token tree
if enabled
                if 
self.config.show_token_tree and 
token_tree:
                    content = 
token_tree + "\n\n" + content

                # Generate summary
                summary = f"URL 
processed: {path}\n"
                summary += f"Title:
{title}\n"
                summary += f"Output
file: {file_name}\n"
                if 
self.split_output_dir:
                    summary += (
                        f"Split 
files output directory: 
{self.split_output_dir}\n"
                    )
                if 
self.config.show_token_tree:
                    summary += 
f"Token Tree generated for URL 
content\n"

                return summary, 
tree, content

            except Exception as e:
                raise 
ValueError(f"Error processing URL: 
{str(e)}")
        else:
            path_obj = Path(path)
            if not 
path_obj.exists():
                raise 
ValueError(f"Path does not exist: 
{path}")
            return 
self._process_directory(path_obj)

    def _process_file(
        self, file_path: Path, 
relative_path: Path
    ) -> Optional[Dict]:
        """Process a single file, 
using markitdown if enabled"""
        self.log_debug(f"Processing
file: {file_path}")

        try:
            if 
self.config.use_markitdown:
                file_ext = 
os.path.splitext(str(file_path))[1]
.lower()
                if (
                    self.config.mar
kitdown_extensions is not None
                    and file_ext in
self.config.markitdown_extensions
                ):
                    try:
                        self.log_de
bug(f"Attempting to process with 
markitdown")
                        assert 
self.markitdown is not None
                        result = 
self.markitdown.convert(str(file_pa
th))
                        self.log_de
bug("Successfully processed with 
markitdown")
                        return {
                            "path":
str(relative_path),
                            "conten
t": result.text_content,
                        }
                    except 
(FileConversionException, 
UnsupportedFormatException) as e:
                        self.log_de
bug(
                            f"MarkI
tDown couldn't process {file_path}:
{str(e)}"
                        )
                    except 
Exception as e:
                        self.log_de
bug(
                            f"Error
with MarkItDown processing 
{file_path}: {str(e)}"
                        )

            # Fall back to normal 
reading
            self.log_debug("Attempt
ing normal file reading")
            with open(file_path, 
"r", encoding="utf-8", 
errors="ignore") as f:
                content = f.read()
                self.log_debug("Suc
cessfully read file normally")
                return {"path": 
str(relative_path), "content": 
content}
        except Exception as e:
            self.log_debug(f"Error 
processing file: {str(e)}")
            return None

    def write_split_files(self, 
files: List[Dict], base_path: Path)
-> None:
        """Write individual files 
for each processed document.

        Args:
            files: List of 
dictionaries containing file paths 
and contents
            base_path: Base path 
for creating the output directory 
structure
        """
        if not 
self.split_output_dir:
            return

        output_dir = 
Path(self.split_output_dir)
        output_dir.mkdir(parents=Tr
ue, exist_ok=True)

        for file_info in files:
            # Generate a unique 
identifier
            file_uuid = 
str(uuid.uuid4())

            # Create output file 
path
            output_file = 
output_dir / f"{file_uuid}.txt"

            # Prepare content with 
metadata header
            content = (
                f"Original Path: 
{file_info['path']}\n"
                f"Base Directory: 
{base_path}\n"
                f"UUID: 
{file_uuid}\n"
                f"{'=' * 50}\n\n"
                f"{file_info['conte
nt']}"
            )

            # Write the file
            with open(output_file, 
"w", encoding="utf-8", 
errors="ignore") as f:
                f.write(content)

    def _process_directory(
        self, path: Path, 
original_path: Optional = None
    ) -> Tuple:
        """Internal method to 
process a directory"""
        files: List[Dict] = []

        # If target_dir is 
specified, look only in that 
subdirectory
        if self.config.target_dir:
            base_path = path / 
self.config.target_dir
            if not 
base_path.exists():
                raise ValueError(
                    f"Target 
directory not found: 
{self.config.target_dir}"
                )
            path = base_path

        for root, dirs, filenames 
in os.walk(path):
            # Filter out excluded 
directories
            dirs[:] = 

            for filename in 
filenames:
                file_path = 
Path(root) / filename
                if 
self.should_process_file(file_path)
:
                    relative_path =
file_path.relative_to(path)
                    result = 
self._process_file(file_path, 
relative_path)
                    if result:
                        files.appen
d(result)

        # Write split files if 
output directory is specified
        if self.split_output_dir:
            self.write_split_files(
files, path)

        # Generate token tree if 
enabled
        token_tree = ""
        if 
self.config.show_token_tree:
            self.log_debug("Generat
ing token tree...")
            token_tree = 
self.generate_token_tree(files, 
path)

        # Generate tree
        tree = "Documentation 
Structure:\n"
        for file in files:
            tree += f"â””â”€â”€ 
{file['path']}\n"

        # Generate content
        content = "\n\n".join(
            [
                f"=================
===============================\n"
                f"File: 
{f['path']}\n"
                f"=================
===============================\n"
                f"{f['content']}"
                for f in files
            ]
        )

        # Append token tree if 
enabled
        if 
self.config.show_token_tree and 
token_tree:
            content = token_tree + 
"\n\n" + content

        # Generate summary
        summary = f"Path analyzed: 
{original_path or path}\n"
        summary += f"Files 
processed: {len(files)}\n"
        if self.config.target_dir:
            summary += f"Target 
directory: 
{self.config.target_dir}\n"
        if 
self.config.use_markitdown:
            summary += "Using 
MarkItDown for compatible files\n"
            if 
self.config.markitdown_extensions:
                summary += 
f"MarkItDown extensions: {', 
'.join(self.config.markitdown_exten
sions)}\n"
        if self.branch:
            summary += f"Git 
branch: {self.branch}\n"
        if self.split_output_dir:
            summary += f"Split 
files output directory: 
{self.split_output_dir}\n"
        if 
self.config.show_token_tree:
            summary += f"Token Tree
generated with {len(files)} 
files\n"

        return summary, tree, 
content


===================================
=============
File: src/readium/cli.py
===================================
=============
from pathlib import Path
from typing import Literal, cast  #
AÃ±adimos cast para el tipado

import click
from rich.console import Console
from rich.table import Table

from .config import URL_MODES  # 
Importamos URL_MODES para el tipado
from .config import (
    DEFAULT_EXCLUDE_DIRS,
    DEFAULT_INCLUDE_EXTENSIONS,
    MARKITDOWN_EXTENSIONS,
)
from .core import ReadConfig, 
Readium, is_url
from .utils.error_handling import 
print_error

console = Console()


@click.command(
    help="""
Read and analyze documentation from
directories, repositories, or URLs.

Examples:
    # Process a local directory
    readium /path/to/directory

    # Process a Git repository
    readium 
https://github.com/username/reposit
ory

    # Process a webpage and convert
to Markdown
    readium 
https://example.com/docs

    # Process a webpage with custom
output
    readium 
https://example.com/docs -o docs.md

    # Save output to a file
    readium /path/to/directory -o 
output.md

    # Generate split files from a 
webpage
    readium 
https://example.com/docs 
--split-output ./markdown-files/

    # Exclude specific file 
extensions
    readium /path/to/directory 
--exclude-ext .json --exclude-ext 
.yml

    # Exclude multiple directories 
(using -x multiple times)
    readium /path/to/directory -x 
dir1 -x dir2

Note: Do not use empty values with 
-x/--exclude-dir. Each value must 
be a valid directory name.
"""
)
@click.argument("path", type=str)
@click.option(
    "--target-dir", "-t", 
help="Target subdirectory to 
analyze (for directories)"
)
@click.option(
    "--branch", "-b", 
help="Specific Git branch to clone 
(only for Git repositories)"
)
@click.option(
    "--max-size",
    "-s",
    type=int,
    default=5 * 1024 * 1024,
    help="Maximum file size in 
bytes (default: 5MB)",
)
@click.option(
    "--output", "-o", 
type=click.Path(), help="Output 
file path for combined results"
)
@click.option(
    "--split-output",
    type=click.Path(),
    help="Directory path for split 
output files (each file gets its 
own UUID-named file)",
)
@click.option(
    "--exclude-dir",
    "-x",
    multiple=True,
    help="Additional directories to
exclude (for directories)",
)
@click.option(
    "--include-ext",
    "-i",
    multiple=True,
    help="Additional extensions to 
include (for directories)",
)
@click.option(
    "--url-mode",
    type=click.Choice(["full", 
"clean"]),
    default="clean",
    help="URL processing mode: 
'full' preserves all content, 
'clean' extracts main content only 
(default: clean)",
)
@click.option(
    "--exclude-ext",
    "-e",
    multiple=True,
    help="File extensions to 
exclude from processing (can be 
specified multiple times, e.g. 
--exclude-ext .json --exclude-ext 
.yml)",
)
@click.option(
    "--debug/--no-debug",
    "-d/-D",
    default=False,
    help="Enable debug mode",
)
@click.option(
    "--use-markitdown/--no-markitdo
wn",
    default=False,
    help="Use MarkItDown to convert
compatible document formats (PDF, 
DOCX, etc.)",
)
@click.option(
    "--token-tree/--no-token-tree",
    default=False,
    help="Show a detailed token 
tree with file and directory token 
counts",
)
@click.option(
    "--token-method",
    type=click.Choice(["simple", 
"tiktoken"]),
    default="simple",
    help="Method to calculate 
tokens: 'simple' (word-based) or 
'tiktoken' (OpenAI tokenizer)",
)
def main(
    path: str,
    target_dir: str,
    branch: str,
    max_size: int,
    output: str,
    split_output: str,
    exclude_dir: tuple,
    include_ext: tuple,
    exclude_ext: tuple,
    url_mode: str,
    debug: bool,
    use_markitdown: bool,
    token_tree: bool,
    token_method: str,
):
    """Read and analyze 
documentation from a directory, 
repository, or URL"""
    try:
        # ValidaciÃ³n: no permitir 
valores vacÃ­os en --exclude-dir / 
-x
        for d in exclude_dir:
            if not d or d.strip() 
== "":
                raise 
click.UsageError(
                    "Empty value 
detected for --exclude-dir/-x. 
Please provide a valid directory 
name."
                )

        # Validamos que url_mode 
sea uno de los valores permitidos
        if url_mode not in ("full",
"clean"):
            url_mode = "clean"  # 
Valor por defecto si no es vÃ¡lido

        # Mostrar al usuario la 
lista final de directorios 
excluidos
        final_exclude_dirs = 
DEFAULT_EXCLUDE_DIRS | 
set(exclude_dir)
        if exclude_dir:
            console.print(
                f"Excluding 
directories: {', 
'.join(sorted(final_exclude_dirs))}
"
            )

        config = ReadConfig(
            max_file_size=max_size,
            exclude_dirs=final_excl
ude_dirs,
            include_extensions=DEFA
ULT_INCLUDE_EXTENSIONS | 
set(include_ext),
            exclude_extensions=set(
exclude_ext),
            target_dir=target_dir,
            url_mode=cast(
                URL_MODES, url_mode
            ),  # Usamos cast para 
que mypy entienda el tipo
            use_markitdown=use_mark
itdown,
            markitdown_extensions=M
ARKITDOWN_EXTENSIONS.copy()
            if use_markitdown
            else set(),
            debug=debug,
            show_token_tree=token_t
ree,
            token_calculation=token
_method,
        )

        reader = Readium(config)
        if split_output:
            reader.split_output_dir
= split_output

        summary, tree, content = 
reader.read_docs(path, 
branch=branch)

        if output:
            with open(output, "w", 
encoding="utf-8") as f:
                f.write(f"Summary:\
n{summary}\n\n")
                f.write(f"Tree:\n{t
ree}\n\n")
                f.write(f"Content:\
n{content}")
            console.print(f"Results
saved to {output}")
        else:
            console.print("Summary:
")
            console.print(summary)
            console.print("\nTree:"
)
            console.print(tree)
            console.print("\nConten
t:")
            try:
                console.print(conte
nt)
            except Exception as e:
                # Handle 
unprintable content
                console.print(
                    "\nError 
displaying content on screen. Check
the output file for details."
                )
                if not output:
                    output = 
"output.txt"
                with open(output, 
"w", encoding="utf-8") as f:
                    f.write(f"Summa
ry:\n{summary}\n\n")
                    f.write(f"Tree:
\n{tree}\n\n")
                    f.write(f"Conte
nt:\n{content}")
                console.print(f"Con
tent saved to {output}")

    except Exception as e:
        print_error(console, 
str(e))
        raise click.Abort()


if __name__ == "__main__":
    main()


===================================
=============
File: 
src/readium/utils/error_handling.py
===================================
=============
import rich.errors
from rich.console import Console


def print_error(console: Console, 
message: str) -> None:
    """Safely print error messages 
that might contain markup-like 
content.

    Args:
        console: Rich console 
instance for output
        message: Error message that
might contain markup-like content
    """
    try:
        console.print(f"Error: 
{message}")
    except rich.errors.MarkupError:
        # Fallback to plain text if
markup fails
        console.print(f"Error: 
{message}", style="red", 
markup=False)

